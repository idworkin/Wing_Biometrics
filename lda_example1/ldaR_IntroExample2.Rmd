## Extending "classification" approaches with lda, qda, etc..

Author: Ian Dworkin. Created: April 14/2014

This continues on from the first tutoria into classifiying observations into classes for purposes of future predictions. In particular we will utilize so-called **supervised learning** approaches like _linear discriminants analysis_ (lda) _quadratic discriminants analysis_ (qda) and a number of other approaches like _support vector machines_ (svm) and non-parametric lda (mda). For all of this I am more or less using the approach from *R in a nutshell* by Joseph Adler (chapter 21). It is a useful `R` reference. 

In addition (and unlike the first tutorial), I will be subsetting the data into a training and testing partitions.

First we call the libraries we want to use (note I am not making any statements of which ones to use, just demonstrating performance on a very specific datasets).
```{r libraries}
require(MASS)     # contains lda() and qda() functions
require(sampling) # easier way to generate subsets of data
require(mda)      # flexible discriminant analysis and mixture discrimant analysis
require(class)    # k nearest neighbours (knn)
#require(rpart)    # Classification and regression trees (CART)
require(adabag)   # bagging()
require(ada)      # boosting function, ada()
require(nnet)     # neural net function, nnet()
require(e1071)    # svm()
require(randomForest) # randomForest() 
```

Now we read in data. Here we are using 15, 2-dimensional landmarks on *Drosophila* wings
```{r data}
wings <- read.csv("~/Dropbox/WingBiometrics2014/PredationWingsALL.csv", h=T)
```

### Notes on this data.
1. The landmarks were acquired "manually" from images using the ImageJ plug-in from Chris Klingenberg. This is not the 58 dimensional data (landmarks and semi-landmarks) from the semi-automated [wing machine](http://bio.fsu.edu/~dhoule/Software/) software from the lab of Dr. David Houle that we normally use these days (2008-present).
2. These images are from an analysis of phenotypic selection of juvenile mantids on *Drosophila melanogaster*.
3. For the purposes of this overview, we only care about the shape data and sex of flies. We are going to ignore other variables (like survivorship)
4. Side refers to Left, Right or unknown (from wings that fell off when the flies were being eaten by predator). We should take care of this to avoid pseudo-replication, but for the moment we will ignore it for the moment, but will come back to it. Do not ignore it for a real analysis.
5. Since we are starting by examining sex, we should also include size as variable, or at least use size corrected shape variables. Again, for the purposes of getting this all started, we are ignoring it.
6.Importanly, since we are using procrustes superimposed data that has been registered (centered) and scaled to centroid size, we only have 26 dimensions, despite having thirty variables. Thus we need to extract the first 26 principal components from the shape data (which contains **ALL** the information)

Let's look at the structure of the data object.
```{r}
str(wings)
```

### Extracting the principal components 
We will use `prcomp()` as this uses singular value decomposition which is a bit more robust than eigendecomposition. 

```{r princomp}
wings_pc <- prcomp(wings[,9:38])
summary(wings_pc)
head(wings_pc$x[,1:26]) # All of the variables we need
wings <- data.frame(wings, wings_pc$x[,1:26]) # appended the PCs
```


### Back to the important stuff
In particular we are interested in how many observations we have for each sex.
```{r table}
tab1 <- table(wings$Sex)
tab1
```
So we have `r tab1[1]` females and `r tab1[2]` males in this data set. For subsetting we want to use ~2/3 for the training set and ~1/3 for test set, so `r round(tab1[1]*(2/3))` for females and `r round(tab1[2]*(2/3))` for males. We will do this using the `strata()` in the sampling library.

```{r strata}
wings_strata <- strata(wings, stratanames=c("Sex"), method="srswor",
    size=c( round(tab1[1]*(2/3)), round(tab1[2]*(2/3))))

names(wings_strata)    
```

`ID_unit` provides the row number. We could have also done this with the `sample(,replace=FALSE)` by specifying probabilities, and accounting for both sexes, but this should be easier. To create the training and test sets we will utilize the index for matching observations using `ID_unit`.
 
```{R subsetting}
wings_2 <- wings[, c(3, 39:64)] # Just extracting the variables needed for this tutorial
wings_training <- wings_2[rownames(wings_2) %in% wings_strata$ID_unit, ]
wings_test <- wings_2[!rownames(wings_2) %in% wings_strata$ID_unit, ] # notice the '!'
nrow(wings_training)
nrow(wings_test)
nrow(wings)
``` 

## linear discriminant analysis.

I am running the lda a bit different from how I performed it in the previous tutorial. Instead of writing out the left and right hand sides of the model, I am going to do it all internal to the call to `lda()`. 

We start by running this on our training set as follows. Note we had to set the tolerance pretty low as the matrix was difficult to invert.
```{r lda_1}
linDiscrim_1 <- lda(formula=Sex ~.,data = wings_training, tol = 1.0e-4, CV=FALSE)
```

We can ask which ones did lda classify correctly, as compared to the true sex. We can check this using a table, which will make this easier to see and use. Note `CV=FALSE` needs to be set in `lda()` for this approach to work. Not sure why they set it up that way. Does not really matter since we do not want to use 1-Fold cross validation.

```{r predict_table}
lda_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(linDiscrim_1, newdata=wings_training)$class)
lda_training_table                          
```
Which results in `r 100*sum(diag(lda_training_table)/sum(lda_training_table))` percent correct classification.

How about for the training set? We do it almost identically in terms of generating the table.

```{r predict_table_test}
lda_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(linDiscrim_1, newdata=wings_test)$class)
lda_test_table                          
```
Which results in `r 100*sum(diag(lda_test_table)/sum(lda_test_table))` percent correct classification. So it seems like our linear discriminant classifier did pretty well to start with.

## quadratic discriminant analysis

Now we move on to quadratic discriminant analysis, with the `qda()` in the MASS library. This has almost the same function call. Indeed many of the functions we will use for classification do.

```{r qda_1}
qda_1 <- qda(formula=Sex ~.,data = wings_training, tol = 1.0e-4)
qda_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(qda_1, newdata=wings_training)$class)
qda_training_table                          

qda_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(qda_1, newdata=wings_test)$class)
qda_test_table                          
```
Which results in `r 100*sum(diag(qda_training_table)/sum(qda_training_table))` percent correct classification for the training data and `r 100*sum(diag(qda_test_table)/sum(qda_test_table))` percent correct classification for the test data.

## Flexible discriminant analysis (FDA)

This uses a non-parametric regression instead of the 'linear' regression type approach in lda. We will use the `fda()` function in the mda library. Otherwise the syntax is similar.

```{r fda_1}
fda_1 <- fda(formula=Sex ~.,data = wings_training)
fda_1
fda_1$confusion
fda_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(fda_1, newdata=wings_training, type="class"))
fda_training_table                          

fda_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(fda_1, newdata=wings_test, type="class"))
fda_test_table                          
```
Which results in `r 100*sum(diag(fda_training_table)/sum(fda_training_table))` percent correct classification for the training data and `r 100*sum(diag(fda_test_table)/sum(fda_test_table))` percent correct classification for the test data.

## mixture discrimant analysis
`mda()` is used.


```{r mda_1}
mda_1 <- mda(formula=Sex ~.,data = wings_training)
mda_1
mda_1$confusion
mda_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(mda_1, newdata=wings_training))
mda_training_table                          

mda_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(mda_1, newdata=wings_test))
mda_test_table  
```

Which results in `r 100*sum(diag(mda_training_table)/sum(mda_training_table))` percent correct classification for the training data and `r 100*sum(diag(mda_test_table)/sum(mda_test_table))` percent correct classification for the test data.

## k nearest neighbours

Using the `knn()`. The `k=1` specifies the number of nearest neighbours to use (defaults to one). Important to tune this. Looks like you need to make sure that only the numeric parts enter.

```{r knn}
wings_knn <- knn(train=wings_training[, -1], test=wings_test[,-1], cl=wings_training$Sex, k=1, prob=TRUE)
summary(wings_knn)

table_knn <- table(predicted=wings_knn, actual=wings_test$Sex)
table_knn
```
Which means we get `r 100*sum(diag(table_knn)/sum(table_knn))`, which is much lower than with other methods.

### Trying a different k

Let us try a different value of 'k' such as k=5. I am not sure (yet) whether there is an automated way to find the best k, but we could always write a for loop if need be.

```{r knn_k5}
wings_knn_k5 <- knn(train=wings_training[, -1], test=wings_test[,-1], 
    cl=wings_training$Sex, k=5, prob=TRUE)
summary(wings_knn_k5)

table_knn_k5 <- table(predicted=wings_knn_k5, actual=wings_test$Sex)
table_knn_k5
```
Which means we get `r 100*sum(diag(table_knn_k5)/sum(table_knn_k5))` percent. Still not great.

## Bagging
Using the `bagging()` in the `adabag` library. This is a bit slow.

```{r bag_1}
bag_1 <- bagging(formula=Sex ~.,data = wings_training)

bag_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(bag_1, newdata=wings_training)$class)
bag_training_table                          

bag_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(bag_1, newdata=wings_test)$class)
bag_test_table                          
```

Which results in `r 100*sum(diag(bag_training_table)/sum(bag_training_table))` percent correct classification for the training data and `r 100*sum(diag(bag_test_table)/sum(bag_test_table))` percent correct classification for the test data.

## boosting
Using the `ada()` in the `ada` library
```{r boo_1}
boo_1 <- ada(formula=Sex ~.,data = wings_training, loss="logistic")

boo_1

boo_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(boo_1, newdata=wings_training))
boo_training_table                          

boo_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(boo_1, newdata=wings_test))
boo_test_table                          
```

Which results in `r 100*sum(diag(boo_training_table)/sum(boo_training_table))` percent correct classification for the training data and `r 100*sum(diag(boo_test_table)/sum(boo_test_table))` percent correct classification for the test data.

## Neural networks

`nnet()` in `nnet` library.

```{r nnet}
nnet_1 <- nnet(formula=Sex ~.,data = wings_training, size=10, decay=0)

nnet_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(nnet_1, type="class"))
nnet_training_table                          

nnet_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(nnet_1, newdata=wings_test, type="class"))
nnet_test_table                          

```
Which results in `r 100*sum(diag(nnet_training_table)/sum(nnet_training_table))` percent correct classification for the training data and `r 100*sum(diag(nnet_test_table)/sum(nnet_test_table))` percent correct classification for the test data. It is important to evaluate some of the tuning parameters for this approach.


## Support vector machines (SVMs)

Using the `svm()` in the `e1071` library.

```{r svm}
wings_svm <- svm(Sex ~., data = wings_training)

svm_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(wings_svm, type="class"))
svm_training_table                          

svm_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(wings_svm, newdata=wings_test, type="class"))
svm_test_table                          

```

Which results in `r 100*sum(diag(svm_training_table)/sum(svm_training_table))` percent correct classification for the training data and `r 100*sum(diag(svm_test_table)/sum(svm_test_table))` percent correct classification for the test data. It is important to evaluate some of the tuning parameters for this approach.


## random forests

Using the `randomForest()` in the `randomForest` library.

```{r randomForest}
wings_rf <- randomForest(Sex ~., data = wings_training)
wings_rf

rf_training_table <- table(actual = wings_training$Sex,
                          predicted = predict(wings_rf, type="class"))
rf_training_table                          

rf_test_table <- table(actual = wings_test$Sex,
                          predicted = predict(wings_rf, newdata=wings_test, type="class"))
rf_test_table                          

```

Which results in `r 100*sum(diag(rf_training_table)/sum(rf_training_table))` percent correct classification for the training data and `r 100*sum(diag(rf_test_table)/sum(rf_test_table))` percent correct classification for the test data. It is important to evaluate some of the tuning parameters for this approach.

