<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>A brief tutorial into &#39;classification&#39; analyses (lda, qda,&hellip;)</title>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}

pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}
</style>



</head>

<body>
<h1>A brief tutorial into &#39;classification&#39; analyses (lda, qda,&hellip;)</h1>

<p>This is a brief tutorial into classifiying observations into classes for purposes of future predictions. In particular we will utilize so-called <strong>supervised learning</strong> approaches like <em>linear discriminants analysis</em> (lda) quadratic discriminants analysis (qda) and a number of other approaches.</p>

<p>First we call the libraries we want to use</p>

<pre><code class="r">require(MASS)  # contains lda() and qda() functions
</code></pre>

<p>Now we read in data. Here we are using 15, 2-dimensional landmarks on <em>Drosophila</em> wings</p>

<pre><code class="r">wings &lt;- read.csv(&quot;~/Dropbox/WingBiometrics2014/PredationWingsALL.csv&quot;, h = T)
</code></pre>

<h3>Some notes on this data.</h3>

<ol>
<li>The landmarks were acquired &ldquo;manually&rdquo; from images using the ImageJ plug-in from Chris Klingenberg. This is not the 58 dimensional data (landmarks and semi-landmarks) from the semi-automated <a href="http://bio.fsu.edu/%7Edhoule/Software/">wing machine</a> software from the lab of Dr. David Houle that we normally use these days (2008-present).</li>
<li>These images are from an analysis of phenotypic selection of juvenile mantids on <em>Drosophila melanogaster</em>.</li>
<li>For the purposes of this overview, we only care about the shape data and sex of flies. We are going to ignore other variables (like survivorship)</li>
<li>Side refers to Left, Right or unknown (from wings that fell off when the flies were being eaten by predator). We should take care of this to avoid pseudo-replication, but for the moment we will ignore it for the moment, but will come back to it. Do not ignore it for a real analysis.</li>
<li>Since we are starting by examining sex, we should also include size as variable, or at least use size corrected shape variables. Again, for the purposes of getting this all started, we are ignoring it.</li>
</ol>

<p>Let&#39;s look at the structure of the data object.</p>

<pre><code class="r">str(wings)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    988 obs. of  38 variables:
##  $ Unique_ID        : Factor w/ 971 levels &quot;G4_F_C_1_U&quot;,&quot;G4_F_C_10_U&quot;,..: 81 82 83 84 85 86 87 88 89 90 ...
##  $ Population       : Factor w/ 3 levels &quot;G4&quot;,&quot;G9&quot;,&quot;S4&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ Sex              : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Treatment        : Factor w/ 3 levels &quot;C&quot;,&quot;D&quot;,&quot;S&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Individual       : int  1 1 2 2 3 3 4 4 5 5 ...
##  $ Side             : Factor w/ 3 levels &quot;L&quot;,&quot;R&quot;,&quot;U&quot;: 1 2 1 2 1 2 1 2 1 2 ...
##  $ Centroid.Size    : num  2.28 2.28 2.6 2.59 2.78 ...
##  $ Log.Centroid.Size: num  0.823 0.823 0.954 0.952 1.021 ...
##  $ ProcCoord1       : num  0.25 0.249 0.249 0.248 0.25 ...
##  $ ProcCoord2       : num  0.0697 0.0693 0.0688 0.0691 0.0687 ...
##  $ ProcCoord3       : num  0.239 0.241 0.239 0.241 0.241 ...
##  $ ProcCoord4       : num  0.0227 0.0239 0.0225 0.0227 0.0231 ...
##  $ ProcCoord5       : num  0.267 0.266 0.269 0.268 0.267 ...
##  $ ProcCoord6       : num  -0.00989 -0.00954 -0.01114 -0.01197 -0.00808 ...
##  $ ProcCoord7       : num  0.206 0.206 0.207 0.208 0.208 ...
##  $ ProcCoord8       : num  -0.0543 -0.0529 -0.0541 -0.0534 -0.0551 ...
##  $ ProcCoord9       : num  0.198 0.198 0.198 0.199 0.197 ...
##  $ ProcCoord10      : num  -0.031 -0.0317 -0.0316 -0.0319 -0.0325 ...
##  $ ProcCoord11      : num  0.173 0.171 0.168 0.168 0.17 ...
##  $ ProcCoord12      : num  0.0234 0.0241 0.0252 0.0248 0.0251 ...
##  $ ProcCoord13      : num  0.138 0.138 0.141 0.141 0.135 ...
##  $ ProcCoord14      : num  0.0877 0.0887 0.0861 0.0872 0.0861 ...
##  $ ProcCoord15      : num  0.0522 0.0566 0.062 0.0652 0.0664 ...
##  $ ProcCoord16      : num  0.0214 0.0215 0.0208 0.0214 0.0199 ...
##  $ ProcCoord17      : num  0.0533 0.0552 0.0647 0.0658 0.0689 ...
##  $ ProcCoord18      : num  -0.00409 -0.00452 -0.00366 -0.00254 -0.00355 ...
##  $ ProcCoord19      : num  -0.0809 -0.084 -0.0891 -0.0915 -0.086 ...
##  $ ProcCoord20      : num  -0.0304 -0.0338 -0.0277 -0.0269 -0.0302 ...
##  $ ProcCoord21      : num  -0.075 -0.0745 -0.0862 -0.0886 -0.0877 ...
##  $ ProcCoord22      : num  -0.0957 -0.0976 -0.0951 -0.095 -0.0994 ...
##  $ ProcCoord23      : num  -0.309 -0.313 -0.319 -0.317 -0.329 ...
##  $ ProcCoord24      : num  0.169 0.168 0.161 0.16 0.157 ...
##  $ ProcCoord25      : num  -0.482 -0.478 -0.477 -0.476 -0.473 ...
##  $ ProcCoord26      : num  0.0515 0.0535 0.0499 0.0483 0.0493 ...
##  $ ProcCoord27      : num  -0.458 -0.456 -0.454 -0.456 -0.453 ...
##  $ ProcCoord28      : num  -0.0352 -0.0333 -0.0323 -0.031 -0.0243 ...
##  $ ProcCoord29      : num  -0.172 -0.174 -0.173 -0.174 -0.174 ...
##  $ ProcCoord30      : num  -0.184 -0.185 -0.179 -0.181 -0.176 ...
</code></pre>

<p>In particular we are interested in how many observations we have for each sex.</p>

<pre><code class="r">table(wings$Sex)
</code></pre>

<pre><code>## 
##   F   M 
## 583 405
</code></pre>

<p>So we have 583 females and 405 males in this data set.</p>

<h2>linear discriminant analysis.</h2>

<p>Normally we would start by subsetting the data into a &#39;training&#39; set and a &#39;validation set&#39;. We will do that below, but first let&#39;s go over some of the basics.</p>

<p>For convenience and clarity I am seperating out the left and right hand sides of the equation. There are other ways of doing this as well. Keep in mind that for linear discrimant analysis the left and right hand side of the equation are &#39;reversed&#39; relative to a general linear model. THat is the categorical variable is now on the LHS.</p>

<p>Putting together right hand side of the model (to make life easier for inputting)</p>

<pre><code class="r">RHS &lt;- paste(&quot;ProcCoord&quot;, 1:26, sep = &quot;&quot;, collapse = &quot; + &quot;)
</code></pre>

<p>It is worth taking a look at what has been output</p>

<pre><code class="r">RHS
</code></pre>

<pre><code>## [1] &quot;ProcCoord1 + ProcCoord2 + ProcCoord3 + ProcCoord4 + ProcCoord5 + ProcCoord6 + ProcCoord7 + ProcCoord8 + ProcCoord9 + ProcCoord10 + ProcCoord11 + ProcCoord12 + ProcCoord13 + ProcCoord14 + ProcCoord15 + ProcCoord16 + ProcCoord17 + ProcCoord18 + ProcCoord19 + ProcCoord20 + ProcCoord21 + ProcCoord22 + ProcCoord23 + ProcCoord24 + ProcCoord25 + ProcCoord26&quot;
</code></pre>

<p>Now we put this all together into a formula</p>

<pre><code class="r">DiscrimEqn &lt;- as.formula(paste(&quot;Sex ~ &quot;, RHS, sep = &quot;&quot;, collapse = &quot;&quot;))
</code></pre>

<p>Once again let&#39;s take a look at it</p>

<pre><code class="r">DiscrimEqn
</code></pre>

<pre><code>## Sex ~ ProcCoord1 + ProcCoord2 + ProcCoord3 + ProcCoord4 + ProcCoord5 + 
##     ProcCoord6 + ProcCoord7 + ProcCoord8 + ProcCoord9 + ProcCoord10 + 
##     ProcCoord11 + ProcCoord12 + ProcCoord13 + ProcCoord14 + ProcCoord15 + 
##     ProcCoord16 + ProcCoord17 + ProcCoord18 + ProcCoord19 + ProcCoord20 + 
##     ProcCoord21 + ProcCoord22 + ProcCoord23 + ProcCoord24 + ProcCoord25 + 
##     ProcCoord26
</code></pre>

<h4>Now we perform the lda</h4>

<p>For the same model, we will need to run it twice. For some reason when we set the cross-validation flag to CV=T, it does not provide the vector of discriminations </p>

<pre><code class="r">linDiscrim_0 &lt;- lda(DiscrimEqn, data = wings, CV = F)
</code></pre>

<p>Since the supervised variable we are interested in (sex) has only two levels, the lda will only produce one vector that discriminantes (we are only discriminating in a single dimension).</p>

<pre><code class="r">linDiscrim_0$scaling
</code></pre>

<pre><code>##                  LD1
## ProcCoord1   -34.489
## ProcCoord2   177.933
## ProcCoord3    16.768
## ProcCoord4  -179.750
## ProcCoord5    -6.883
## ProcCoord6   109.968
## ProcCoord7  -112.176
## ProcCoord8    87.017
## ProcCoord9    45.013
## ProcCoord10 -105.772
## ProcCoord11  -43.168
## ProcCoord12   86.987
## ProcCoord13  -80.005
## ProcCoord14   35.794
## ProcCoord15   12.771
## ProcCoord16   51.418
## ProcCoord17  102.529
## ProcCoord18  -40.635
## ProcCoord19    6.644
## ProcCoord20 -116.080
## ProcCoord21  -81.341
## ProcCoord22  247.453
## ProcCoord23   -8.985
## ProcCoord24  267.234
## ProcCoord25   46.402
## ProcCoord26   12.366
</code></pre>

<p>We run the same model, only this time with CV=T.</p>

<pre><code class="r">linDiscrim_1 &lt;- lda(DiscrimEqn, data = wings, CV = T)
</code></pre>

<p>Note that we set flag for cross validation to TRUE. This is simply leave-one-out cross-validation, which evaluates the predictive performance, but it is not as good as a true training and test set like we will perform later.</p>

<p>We can look at the calls for the classifications (not true sex of fly, but what lda is calling it).</p>

<pre><code class="r">linDiscrim_1$class
</code></pre>

<pre><code>##   [1] F F F F F F F F F F F F F F F F F F F F F F F F M F F F F F F F F F F
##  [36] F F F F M F F F F F F F F F F M F F F F F M F F F F F F M F F M F F F
##  [71] F F F M F F F M M M F F F F F F F F F F F F F F F F F F F F F F F F F
## [106] F F F F M F F F F F F F F F F F F F F F F F F F M F F F F F F F F F F
## [141] F F F F F F M F F M F F F F F F F F F F F F F M M F F F F F F F F F F
## [176] F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F F
## [211] F F F F F F F F F F F F F F F F F F F F F F F F F F M F F F F F F F F
## [246] M M F F M F F F F F F F F F F F F F F F F F F F F F F F M M M M M M M
## [281] M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M
## [316] M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M F
## [351] F M M M M M M M M M M M F M M F F M M M M M M M M M F M M F M M M M M
## [386] M M M F M M M M M M M M M F M M M M F M M M M F M M M M F M M M M M M
## [421] M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M
## [456] M M M M M M M F F F M M M M F F F F F M F F F F F F F F F F F F F F F
## [491] F F F F F F F F F F F F F F F F F M F F F F F F F F F F F F F F F F F
## [526] F F F F F F F F F F F F F F F F F F F F M M F F F F F F F F F F F F F
## [561] F F F F F M F F F F F F F F F F F F F F F F F F F F F F F F F F F F F
## [596] F F F F F F F F F F F F F F F M F F F F F F F F F F F F F F F F F F F
## [631] F F F F F F F F F F F F F F F F F F M F F F F M M F F F F F F F F F F
## [666] F F F F F F F F M F F F F F F F F F M F F F F F F F F F F F F F F F F
## [701] F F F F F F F F F F F F F F M F F F F F F F F F F F F M M M M M M M M
## [736] M M M M M M M M M M M M M M M M M M M M M M M M M M M M M F M M M M M
## [771] F F M M M M M M M M F M M M F M M M M M M M M M M M M M M M M M M M M
## [806] M M M M M M M M M M M M M F M M M M M M M M M M M M M M M M M M F F F
## [841] M M F M M M M M M F M M M M M F M M M M M M M M F M M M M M M M M M M
## [876] M M M M M M M M M M M M M M M M F F F F F F F F F F F F F F F F F F F
## [911] F F F F F F F F F F F F F F F F F F F F F F F F F F F F M F F F M M F
## [946] M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M
## [981] M M M M M M M M
## Levels: F M
</code></pre>

<p>and the posterior probabilities for the classifications (we have not specified a prior, so it is flat by default I believe). Here we will just look at the first and last 10 observations.</p>

<pre><code class="r">head(linDiscrim_1$posterior, n = 10)
</code></pre>

<pre><code>##         F         M
## 1  0.9892 0.0107886
## 2  0.9692 0.0308273
## 3  0.9883 0.0116947
## 4  0.9804 0.0195656
## 5  0.9978 0.0022387
## 6  0.9976 0.0023530
## 7  0.9998 0.0001596
## 8  0.9996 0.0003768
## 9  0.9924 0.0075874
## 10 0.9981 0.0018559
</code></pre>

<pre><code class="r">tail(linDiscrim_1$posterior, n = 10)
</code></pre>

<pre><code>##             F      M
## 979 0.0008157 0.9992
## 980 0.0520666 0.9479
## 981 0.0060566 0.9939
## 982 0.2180089 0.7820
## 983 0.0132210 0.9868
## 984 0.0007304 0.9993
## 985 0.0120224 0.9880
## 986 0.0034559 0.9965
## 987 0.0064043 0.9936
## 988 0.0018918 0.9981
</code></pre>

<p>We can ask which ones did lda classify correctly, as compared to the true sex.</p>

<pre><code class="r">linDiscrim_1$class == wings$Sex
</code></pre>

<pre><code>##   [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [12]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [23]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [34]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
##  [45]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
##  [56]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
##  [67] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE
##  [78] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [89]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [100]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
## [111]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [122]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
## [133]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [144]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
## [155]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE
## [166]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [177]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [188]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [199]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [210]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [221]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [232]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [243]  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE
## [254]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [265]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [276]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [287]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [298]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [309]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [320]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [331]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [342]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE
## [353]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
## [364]  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [375]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [386]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [397]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE
## [408]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
## [419]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [430]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [441]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [452]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [463] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [474]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [485]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [496]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [507]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [518]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [529]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [540]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE
## [551]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [562]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [573]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [584]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [595]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [606]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [617]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [628]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [639]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
## [650]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [661]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [672]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [683]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [694]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [705]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
## [716]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [727]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [738]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [749]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [760]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [771] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
## [782]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [793]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [804]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [815]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [826]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [837]  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
## [848]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
## [859]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
## [870]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [881]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [892]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [903]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [914]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [925]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [936]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE
## [947]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [958]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [969]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [980]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
</code></pre>

<p>Importantly we can ask what proportion were correctly identified this way. Again, keep in mind this only used leave-one-out cross-validation, so it is probably not sufficient.</p>

<pre><code class="r">prob_correct &lt;- sum(linDiscrim_1$class == wings$Sex)/length(wings$Sex)
prob_correct
</code></pre>

<pre><code>## [1] 0.9362
</code></pre>

<p>So the lda with 1-fold cross-validation gives us 93.6235 percent correct identification.</p>

<h2>Below I am just checking some of the math. It can be ignored for now</h2>

<p>Computing the discriminant function coefficient vector, a For the two group problem.
First compute means for males and females</p>

<pre><code class="r">males &lt;- wings[wings$Sex == &quot;M&quot;, 9:34]
females &lt;- wings[wings$Sex == &quot;F&quot;, 9:34]
male.means &lt;- colMeans(males)
female.means &lt;- colMeans(females)
</code></pre>

<p>Calculate pooled covariance matrix</p>

<pre><code class="r">pooled.cov &lt;- cov(wings[, 9:34])  # This is S
S.inv &lt;- solve(pooled.cov)  # If you set the tolerance too low, all hell breaks loose, so for this example I am using a covariance matrix of full rank,
</code></pre>

<p>Now compute the discriminant function coefficient vector, a = S[-1]</p>

<pre><code class="r">a = S.inv %*% (male.means - female.means)

# rescaling it to compare to the original vector
a.prime = a * (34.488708/31.918649)
cbind(a.prime, linDiscrim_0$scaling)
</code></pre>

<pre><code>##                           LD1
## ProcCoord1   -34.489  -34.489
## ProcCoord2   177.933  177.933
## ProcCoord3    16.768   16.768
## ProcCoord4  -179.750 -179.750
## ProcCoord5    -6.883   -6.883
## ProcCoord6   109.968  109.968
## ProcCoord7  -112.176 -112.176
## ProcCoord8    87.017   87.017
## ProcCoord9    45.013   45.013
## ProcCoord10 -105.772 -105.772
## ProcCoord11  -43.168  -43.168
## ProcCoord12   86.987   86.987
## ProcCoord13  -80.005  -80.005
## ProcCoord14   35.794   35.794
## ProcCoord15   12.771   12.771
## ProcCoord16   51.418   51.418
## ProcCoord17  102.529  102.529
## ProcCoord18  -40.635  -40.635
## ProcCoord19    6.644    6.644
## ProcCoord20 -116.080 -116.080
## ProcCoord21  -81.341  -81.341
## ProcCoord22  247.453  247.453
## ProcCoord23   -8.985   -8.985
## ProcCoord24  267.234  267.234
## ProcCoord25   46.402   46.402
## ProcCoord26   12.366   12.366
</code></pre>

</body>

</html>
